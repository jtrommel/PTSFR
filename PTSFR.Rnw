\documentclass{tufte-book}
\usepackage{graphicx}  % werken met figuren
\usepackage{gensymb} % werken met wetenschappelijke eenheden\usepackage{geometry}
\usepackage{changepage} % http://ctan.org/pkg/changepage
\usepackage[dutch,british]{babel} % instelling van de taal (woordsplitsing, spellingscontrole)
\usepackage[parfill]{parskip} % Paragrafen gescheiden door witte lijn en geen inspringing
\usepackage[font=small,skip=3pt]{caption} % Minder ruimte tussen figuur/table en ondertitel. Ondertitel klein
\usepackage{capt-of}
\usepackage{indentfirst}
\setlength{\parindent}{0.7cm}
\usepackage{enumitem} % Laat enumerate werken met letters
\usepackage{url}
\usepackage{lipsum}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
% Prints a trailing space in a smart way.
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{amsmath}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of "TeX Unbound" for suggested values.
% See pp. 199-200 of Lamport's "LaTeX" book for details.
%   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.9}	% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\textfraction}{0.1}	% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.8}	% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\setcounter{secnumdepth}{3}

\newcommand{\tthdump}[1]{#1}

\newcommand{\openepigraph}[2]{
  \begin{fullwidth}
  \sffamily\large
    \begin{doublespace}
      \noindent\allcaps{#1}\\ % epigraph
      \noindent\allcaps{#2} % author
    \end{doublespace}
  \end{fullwidth}
}


\usepackage{makeidx}
\makeindex

\title{Practical Time Series Forecasting with R}
\author{Jan Trommelmans}

\begin{document}
\SweaveOpts{concordance=TRUE,prefix.string=PTSFR}
\setkeys{Gin}{width=1.1\marginparwidth} %% Sweave

<<echo=FALSE>>=
library(tidyverse)
library(lubridate)
library(broom)
library(funModeling)
library(forecast)
library(gridExtra)
library(writexl)
library(plotly)
@

% Setting the ggplot theme:
<<echo=FALSE>>=
JT.theme <- theme(panel.border = element_rect(fill = NA, colour = "gray10"),
                  panel.background = element_blank(),
                  panel.grid.major = element_line(colour = "gray85"),
                  panel.grid.minor = element_line(colour = "gray85"),
                  panel.grid.major.x = element_line(colour = "gray85"),
                  axis.text = element_text(size = 8 , face = "bold"),
                  axis.title = element_text(size = 9 , face = "bold"),
                  plot.title = element_text(size = 12 , face = "bold"),
                  strip.text = element_text(size = 8 , face = "bold"),
                  strip.background = element_rect(colour = "black"),
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 9 , face = "bold"),
                  legend.background = element_rect(fill = "white"),
                  legend.key = element_rect(fill = "white"))
@

% Functions



\frontmatter
\chapter*{Practical Time Series Forecasting with R}

\mainmatter

\chapter{Approaching Forecasting}
\section{Forecasting: Where?}
Everywhere

\section{Basic notation}
\begin{itemize}
 \item t=1, 2, 3 : index of time of measurement of the value
 \item $y_{1}, y_{2}, \ldots y_{i}, \ldots$ : value of the time series for t=i
 \item $F_{t}$ : forecasted value for time index t
 \item $F_{t+k}$ : k-step ahead forecast when the forecasting time is t (don't know what that means)
 \item $e_{t}$ : forecast error at time t =$y_{t}-F_{t}$
\end{itemize}

\section{Forecasting process}

\begin{enumerate}
	\item define goal (chapter 1)
	\item get data (chapter 2)
	\item explore and visualise the time series (chapter 2)
	\item pre-process data (chapter 2)
	\item partition the time series (chapter 4)
	\item apply forecasting methods (chapter 5 - 9)
	\item evaluate, compare performance (chapter 3)
	\item implement forecasting system (chapter 10)
\end{enumerate}

\section{Goal definition}

\begin{itemize}
	\item purpose of generating forecasts? \emph{time series analysis}\index{time series!analysis} is about \emph{descriptive modeling}\index{modeling!descriptive} the time series. \emph{time series forecasting}\index{time series!forecasting} is about \emph{predicting}\index{modeling!predictive} future values. Descriptive methods can use data ''from the future" (e.g. in moving averaging), while predictive methods can only rely on present data and past data.
	\item type of forecasts that are needed? \emph{Forecast horizon}\index{forecast!horizon}: how far in the future should we forecast? A forecast horizon $k$ is the number of time steps ahead we have to forecast $(F_{t+k})$. The value of $k$ depends on the purpose of the forecast. Here the element of data availability is important: if the most recent data are two months old, a forecast for next month requires a forecast horizon $k=3$.
	\item how will the forecasts be used? Do we want a numerical result or a binary one (''yes/no"). Who is the client: technocrats with a deep understanding of forecasting, or generalists who simply want to use the forecast?
	\item costs associated with forecast errors?
	\item data available in the future? \emph{Forecast updating}\index{forecast!updating}: forecasting for one point in time, or ongoing. If it is ongoing our forecasting method should be able to take new information into account. A forecast for december 2019 made in januari 2019 can be refreshed when data for februari, march ... 2019 become available.
	\item the level of automation. The level of automation increases when many time series have to be forecast, when it is an ongoing process, when extra data become available during the forecasting period and when less forecasting expertise is available.
\end{itemize}

\chapter{Time Series Data}

\section{Data Collection}

\subsection{Data quality}

\emph{Data quality}\index{data!quality} refers to:
\begin{itemize}
	\item accuracy of measurement
	\item missing values
	\item corrupted data
	\item data entry errors
\end{itemize}

Check if external data\index{data!external} can be more predictive then solely the historic sequence available in a time series.

\subsection{Temporal frequency}

The \emph{frequency}\index{frequency!of data collection} of data collection is not necessarily the right frequency for forecasting purposes. It depends on the forecasting goal. If we want monthly forecasts it is sensible to reduce daily measurements to monthly values. Fine grained data collection introduces \emph{noise}\index{noise} that is not relevant for longer term forecasts and should be filtered out.

Even if forecasts are wanted on at time base $T$ we can still aggregate the collected data on a time base $n*T$, make the forecast model and de-aggregate the forecast to time base $T$ (by a suitable interpolation method).

\subsection{Granularity of the time series}
\emph{Granularity}\index{granularity} refers to additional information present in the time series data that can be used to make subsets. These can be based on geographical information, sociological strata, age groups etc. A higher levels of detail can lead to subsets where the time series value equals zero. This could lead to changing the forecast method from numerical to binary (''yes/no").

\subsection{Domain expertise}

\index{domain expertise}Do we have the knowledge available to decide on the following topics:
\begin{itemize}
	\item which data are we going to collect?
	\item at what frequency?
	\item can we interpret the patterns in the data?
	\item can we identify extreme values?
	\item do the users of our forecast(s) have the knowledge to interpret the results?
\end{itemize}

\section{Time Series Components}

\emph{Time series}\index{time series} are a specific sort of data. In constrast with \emph{cross-secional data}\index{cross-sectional data}, which are multiple measurements taken at the same time, \emph{time series} consist of one measurement taken at different moments in time.

Time series can have the following characteristics:

\begin{enumerate}
  \item error: random fluctuation of values
  \item level: mean value of the series
  \item trend: gradual evolution without repetition
  \item seasonality: periodic behaviour with characteristic period $T_{i}$. Multiple periodicity is possible
\end{enumerate}

The use of \emph{level}\index{level} and \emph{trend}\index{trend} as separate characteristics is different from normal usage in model building where both are incorporated into the model equation. Thus if we model the general behaviour of $y$ as a function of $t$ by a polynomial:
\begin{equation}
y(t)=b_{0} + b_{1}t + b_{2}t^{2} + \ldots b_{i}t^{i} + \ldots = p(t)
\end{equation}

and we define the level as $\bar{y}$ then the \emph{trend} in the sense as defined above is given by:
\begin{equation}
trend = p(t) - \bar{y} = \left( b_{0} - \bar{y} \right) + b_{1}t + b_{2}t^{2} + \ldots b_{i}t^{i} + \ldots 
\end{equation}

The book\sidenote{Practical Time Series Forecasting with R - Galit Shmueli and Kenneth C. Lichtendahl Jr.} refers to examples of \emph{level} and \emph{trend} by Jim Flower (\url{http://techweb.bsu.edu/jcflowers1/rlo/trends.htm}). However, in his paragraph on ''Some Common Types of Trends" he says:

\textit{Trends are often shown graphically (as line graphs) with the level of a dependent variable on the y-axis and the time period on the x-axis. There are different types of trends, including the following:
\begin{itemize}
	\item constant
	\item linear
	\item exponential
	\item damped
\end{itemize}
}

In the example graphs given by Flower, he only uses the word ''trend", and he says nothing about ''level". This gives the impression that ''trend" here is used in the traditional modeling sense i.e. ''trend"=trend+level. In what follows I will only use the characteristic ''level" where needed and consider it to be equal to the average of the ''trend" in the modeling sense of the word. 

Time series can be constructed by \emph{adding} or \emph{multiplying} or \emph{combinations of adding and multiplying} these basic characteristics. \emph{Multiplication} is used when e.g. the amplitude of an seasonal characteristic is linked to the trend. Multiplying a trend with a sine function (seasonality) will increase the amplitude of the sine function when the trend is rising, and decrease the amplitude when the trend is falling. The same can be said for multiplying the trend and the error term: bigger errors when the trend rises, smaller when it falls.

This gives a lot of possible combinations. If we limit ourselves to a maximum of two seasonal elements, and either a completely additive or a completely multiplicative type we get $2^5 = 32$ combinations:

\begin{tabular}{r | c | c}
characteristic & 0 = not present & 1 = present \\
\hline
error & 0 & 1 \\
trend & 0 & 1 \\
seasonality 1 & 0 & 1 \\
seasonality 2 & 0 & 1 \\
type & A & M
\end{tabular}

However, some of these 32 possibilities are not interesting or self evident:
\begin{itemize}
  \item all multiplicative constructed time series where one of the characteristics is 0, have the same end result i.e. zero everywhere
  \item some models without an error term. Where we have only trend the graph is given by the polynomial $p(t)$ (or another function) and  forecasting is a, tentative, extrapolation
\end{itemize}

The interesting ones are:
\begin{enumerate}
  \item additively created time series:
    \begin{itemize}
      \item without error
        \begin{itemize}
          \item trend + seasonality 1
          \item trend + seasonality 1 + seasonality 2
        \end{itemize}
      \item with error
        \begin{itemize}
          \item error
          \item error + trend
          \item error + trend + seasonality 1
          \item error + trend + seasonality 1 + seasonality 2
        \end{itemize}
      \end{itemize}
  \item multiplicatively created time series:
    \begin{itemize}
      \item without error
        \begin{itemize}
          \item trend*seasonality 1
          \item trend*seasonality 1*seasonality 2
        \end{itemize}
      \item with error
        \begin{itemize}
          \item error*trend
          \item error*trend*seasonality 1
          \item error*trend*seasonality 1*seasonality 2
        \end{itemize}
    \end{itemize}
\end{enumerate}

\section{Constructed data sets}
\label{sec:constructed}
\begin{itemize}
  \item number of elements per time series: N=1000
  \item time step unit: 1
  \item error: random from normal distributiion with $\mu=0$, $\sigma=3$. Random number generator seed: 2019
  \item trend: polynomial. We restrict ourselves to models $y=p(x)$ with second degree polynomials (or first degree when $b_{2}=0$) with co\"{e}ffici\"{e}nts $b_{0}=0$, $b_{1}=0.01$ and $b_{2}=0.00005$. 
  \item seasonality 1: sine with amplitude=0 or $3\sigma$, period=$\frac{N}{9}$, phase=0. N not exact multiple of T1
  \item seasonality 2: sine with amplitude=0 or $\sigma$, period=$\frac{N}{39}$, phase=$\frac{\pi}{3}$. N not exaxt multiple of T2
  \item type: additive (''A") or multiplicative (''M")
\end{itemize}

<<echo=FALSE>>=
# Number of elements in the data set
N <- 1000
# Random number generator seed
set.seed(2019)
# error parameters
mu <- 0
sigma <- 3
# trend model parameters
b0 <- 0
b1 <- 0.01
b2 <- 0.00005
# level
level <- b0 + (b1/2)*N + (b2/3)*N^2
# seasonality 1
amp1 <- 3*sigma
teta1 <- 0
T1 <- N/9
# seasonality 2
amp2 <- sigma
teta2 <- pi/3
T2 <- N/39
# constant for combined additive/multiplicative time series
c <- 0.05
@

\newpage
\subsection{Additive constructed time series}
<<echo=FALSE>>=
#
# creating the additive constructed set
#
construct <- data.frame(t = seq(1:N),
                        error = rnorm(N, mean = mu, sd = sigma))
construct %>% mutate(trend = (b0 + b1*t +b2*t^2)) -> construct
construct %>% mutate(season1 = amp1*sin(2*pi*t/T1 + teta1)) -> construct
construct %>% mutate(season2 = amp2*sin(2*pi*t/T2 + teta2)) -> construct
@

<<label=additive, fig=TRUE, include=FALSE, echo=FALSE>>=
p1 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = error), size = 1, color="red") +
  geom_hline(yintercept = mu, linetype = 2) +
  scale_y_continuous(limits= c(-25, 75)) +
  JT.theme
p2 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = error + trend), size = 1, color="red") +
  geom_hline(yintercept = level, linetype = 2) +
  scale_y_continuous(limits= c(-25, 75)) +
  JT.theme
p3 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = error + trend + season1), size = 1, color="red") +
  geom_hline(yintercept = level, linetype = 2) +
  scale_y_continuous(limits= c(-25, 75)) +
  JT.theme
p4 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = error + trend + season1 + season2), size = 1, color="red") +
  geom_hline(yintercept = level, linetype = 2) +
  scale_y_continuous(limits= c(-25, 75)) +
  JT.theme
grid.arrange(p1, p2, p3, p4, nrow=2)
construct %>% mutate(addcon = error + trend + season1 + season2) -> construct
write_xlsx(data.frame(t = construct$t,addcon = construct$addcon), "Data/addcon.xlsx")
@

\begin{figure}
\includegraphics[width=0.7\textwidth]{PTSFR-additive}
\caption{Additive constructed time series}
\label{fig:additive}
\setfloatalignment{b}
\end{figure}

This time series is stored in the data frame \textit{construct} in column \textit{addcon}. It is also stored as an Excel-spreadsheet (\textit{addcon.xlsx}).

\subsection{Multiplicative constructed time series}

The definition of a multiplicative time series is:
\begin{equation}
y(t)=error(t)*trend(t)*seasonality(t)
\end{equation}

<<label=trend, fig=TRUE, include=FALSE, echo=FALSE>>=
p1 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = trend*season1), size=1, color="red") +
  labs(title="") +
  JT.theme
p2 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = trend*(season1 + season2), size=1, color="red")) +
  labs(title="") +
  JT.theme
grid.arrange(p1, p2, nrow=1)
@

<<label=error, fig=TRUE, include=FALSE, echo=FALSE>>=
p1 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = error*trend), size=1, color="red") +
  labs(title="") +
  JT.theme
p2 <- ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = error*trend*season1, size=1, color="red")) +
  labs(title="") +
  JT.theme
grid.arrange(p1, p2, nrow=1)
@

But the multiplication means that $y(t)$ will always be equal to zero whenever one of the factors is zero\sidenote[][-1cm]{\url{https://fs.blog/2016/08/multiplicative-systems/}}. Let's look at some combinations of characteristics:
\begin{itemize}
  \item trend*season: this changes the amplitude of the seasonal component but it loses the overall trend (Figure~\ref{fig:trend})
    \begin{marginfigure}[0cm]
      \includegraphics[width=1\textwidth]{PTSFR-trend}
      \caption{}
      \label{fig:trend}
      \setfloatalignment{b}
    \end{marginfigure}
  \item error*trend and error*trend*season (Figure~\ref{fig:error})
  \begin{marginfigure}[0cm]
      \includegraphics[width=1\textwidth]{PTSFR-error}
      \caption{}
      \label{fig:error}
      \setfloatalignment{b}
    \end{marginfigure}
\end{itemize}

These time series constructions with multiplication do not give the desirede result: the trend only changes the amplitude of the seasonal component and/or the error term, but the trend itself is lost.

\newpage
\subsection{Combined additive and multiplicative constructed time series}
In the end to obtain the goal that both the amplitude of the seasonal terms and the amount of error are influenced by trend we have to combine additive and multiplicative elements in
\begin{equation}
y(t) = trend*(1 + c*(error + season1 + season2)) \quad c=0.05
\end{equation}
resulting in Figure~\ref{fig:multiplicative}.

<<label=multiplicative, fig=TRUE, include=FALSE, echo=FALSE>>=
ggplot(data = construct, aes(x = t)) +
  geom_line(aes(y = trend*(1 + c*(error + season1 + season2))), size=1, color="red") +
  labs(title="") +
  JT.theme
construct %>% mutate(combicon = trend*(1 + c*(error + season1 + season2))) -> construct
write_xlsx(data.frame(t = construct$t,combicon = construct$combicon), "Data/combicon.xlsx")
@

\begin{figure}
\includegraphics[width=0.5\textwidth]{PTSFR-multiplicative}
\caption{multiplicative constructed time series}
\label{fig:multiplicative}
\setfloatalignment{b}
\end{figure}

This time series is stored in the data frame \textit{construct} in column \textit{combicon}.

\section{Visualising Time Series}

A visualisation of the time series will give us a first, visual, indication of the nature of the series. We can look for \emph{missing} or \emph{extreme values}, \emph{unequal spacing} and \emph{patterns}.

A first and obvious plot is a line chart of the series as a function of time. \textit{ggplot} does this very well.

\newthought{Example: Ridership on Amtrak Trains}

<<label=Amdata,fig=TRUE,include=FALSE, echo=FALSE>>=
Amtrak.data <- read.csv("Data/Amtrak data.csv", sep=";", stringsAsFactors = FALSE)
# transforming the ''Month" column into a proper date variable
Amtrak.data %>%  mutate(day = myd(paste0(Month, "-01"))) -> Amtrak.data
Amtrak.data$t <- c(1:nrow(Amtrak.data))
Amtrak.baseplot <- ggplot(data=Amtrak.data) +
                          geom_line(aes(x=t, y=Ridership), size=1, color="red") +
                          labs(title="Amtrak Ridership data") +
                          JT.theme
Amtrak.baseplot
@

\begin{marginfigure}
\includegraphics[width=1\textwidth]{PTSFR-Amdata}
\caption{}
\label{fig:Amdata}
\setfloatalignment{b}
\end{marginfigure}


\newpage
Other operations are:
\subsection{Zooming}\index{visualization!zooming}
\label{subsec:zoomingin}
\newthought{Example} 
We use the time series of the number of vehicles in the Baregg Tunnel.

<<label=Baregg,fig=TRUE,include=FALSE, echo=FALSE>>=
Baregg.data <- read.csv("Data/BareggTunnelTraffic.csv", sep=",", stringsAsFactors = FALSE)
Baregg.data$t <- c(1:nrow(Baregg.data))
Baregg.data$day <- dmy(Baregg.data$day)
Baregg.baseplot <- ggplot(data=Baregg.data) +
  geom_line(aes(x=day, y=number), size=1, color="red") +
  labs(title="Number of vehicles in Baregg Tunnel") +
  JT.theme
p2 <- ggplot(data=Baregg.data) +
  geom_line(aes(x=day, y=number), size=1, color="red") +
  scale_x_date(limits = dmy(c("01-02-2004","31-05-2004")), breaks = dmy(c("01-02-2004", "01-03-2004", "01-04-2004", "01-05-2004", "31-05-2004")))  +
  labs(title="Number of vehicles in Baregg Tunnel\nzooming from 1-Feb-2004 to 31-May-2004") +
  JT.theme
p3 <- ggplot(data=Baregg.data) +
  geom_line(aes(x=day, y=number), size=1, color="red") +
  scale_x_date(limits = dmy(c("01-02-2004","08-02-2004")), breaks = dmy(c("01-02-2004", "02-02-2004", "03-02-2004", "04-02-2004", "05-02-2004", "06-02-2004", "07-02-2004", "08-02-2004")))  +
  labs(title="Number of vehicles in Baregg Tunnel\nzooming week of 1-Feb-2004") +
  JT.theme
grid.arrange(Baregg.baseplot, p2, p3, nrow=3)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-Baregg}
\caption{}
\label{fig:Baregg}
\setfloatalignment{b}
\end{figure}

\newthought{addcon time series}
<<label=addconviz,fig=TRUE,include=FALSE, echo=FALSE>>=
p1 <- ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=addcon), size=1, color="red") +
  labs(title="Additive constructed model\nfull range") +
  JT.theme
p2 <- ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=addcon), size=1, color="red") +
  scale_x_continuous(limits = c(250,500), breaks = seq(250, 500, by=10))  +
  scale_y_continuous(limits = c(-10,40), breaks = seq(-10, 40, by=5))  +
  labs(title="Additive constructed model\nrange = 250 - 500") +
  JT.theme
p3 <- ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=addcon), size=1, color="red") +
  scale_x_continuous(limits = c(275,285), breaks = seq(275, 285, by=1))  +
  scale_y_continuous(limits = c(-5,15), breaks = seq(-5, 15, by=1))  +
  labs(title="Additive constructed model\nrange = 275 - 285") +
  JT.theme
grid.arrange(p1, p2, p3, nrow=3)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-addconviz}
\caption{Various levels of detail}
\label{fig:addconviz}
\setfloatalignment{b}
\end{figure}

First we plot the whole range. Then we determine the range where we can see a few periods of a possible seasonal. Then we go in for some more detail(Figure~\ref{fig:addconviz}). Looking at the top graph I can see a seasonal pattern of approximatively 9 periods over a range from 0 to 1000. A first estimate for the seasonal component is that it has a period of 111 (not bad given that it is N/9). The other, more detailed graphs, do not improve on this.

\newthought{combicon time series}
<<label=combiconviz,fig=TRUE,include=FALSE, echo=FALSE>>=
p1 <- ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=combicon), size=1, color="red") +
  labs(title="Combined constructed model\nfull range") +
  JT.theme
p2 <- ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=combicon), size=1, color="red") +
  scale_x_continuous(limits = c(250,500), breaks = seq(250, 500, by=10))  +
  scale_y_continuous(limits = c(0,35), breaks = seq(0, 35, by=5))  +
  labs(title="Combined constructed model\nrange = 250 - 500") +
  JT.theme
p3 <- ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=combicon), size=1, color="red") +
  scale_x_continuous(limits = c(350,375), breaks = seq(350, 375, by=1))  +
  scale_y_continuous(limits = c(7.5,17.5), breaks = seq(7.5, 17.5, by=2.5))  +
  labs(title="Combined constructed model\nrange = 350 - 375") +
  JT.theme
grid.arrange(p1, p2, p3, nrow=3)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-combiconviz}
\caption{Various levels of detail}
\label{fig:combiconviz}
\setfloatalignment{b}
\end{figure}

First we plot the whole range. Then we determine the range where we can see a few periods of a possible seasonal. Then we go in for some more detail (Figure~\ref{fig:combiconviz}). The top graph shows a seasonal pattern that starts around t=125 and ends at t=1000 after 8 periods. A first estimate for the seasonal component is that it has a period of (1000 - 125)/8=109,4 (again not bad given that it is N/9). The other, more detailed graphs, do not improve on this.

\newthought{Using plotly}

We can turn a \textit{ggplot} into a more flexible \textit{plotly}-object by using the \textbf{plotly}-package and the command \textit{ggplotly(p)} where p is the \textit{ggplot}-object. The full range combined constructed model gets a dynamic zoom window in this way. The result is not a pdf-file, so it cannot be loaded into the Sweave file. But it is a quick tool to do some zooming.

<<echo=FALSE>>=
ggplotly(p1)
@

\newthought{Time Series Objects in R and the parameter frequency}
We can do the visualising perfectly with \textit{ggplot}, which means that az yet we don't need to force the data into a time series object\index{time series object}. Doing so requires you to select a value for the parameter ''frequency"\index{time series!frequency}. First of all: it is \textbf{NOT} a frequency, but a period! Not Hz but sec (or other time scale). While this parameter can be chosen reasonably in certain situations (e.f. the Amtrak data where values are recorded monthly and we can assume a seasonality of 1 year = 12 months), it is (at present) not so clear for the Belragg data or the constructed time series (addcon and combicon). Rob Hyndman\sidenote{\url{https://otexts.org/fpp2/}} gives a few examples:
\begin{itemize}
	\item if you have monthly records, set the frequency to 12. The assumption is that the seasonality has a period of one year
	\item if you have weekly records, set the frequency to 52. Again the assumption is that the seasonality has a period of one year. However: a year is not exactly 52 weeks, but 52,14... However: most time series objects cannot have a non-integer frequency parameter
	\item if you have daily records, set the frequency to 7. Here we assume that many variables will show a weekly pattern (working days on the one hand, weekend on the other). So for the Belragg data is could be sensible to set the parameter frequency to 7.
\end{itemize}

\newthought{Amtrak Riderschip as a time series object}
<<label=Amtrakts, fig=TRUE, include=FALSE, echo=FALSE>>=
ridership.ts <- ts(Amtrak.data$Ridership, start = c(1991,1), end = c(2004,3), frequency = 12)
plot(ridership.ts, xlab = "Time", ylab = "Ridership", ylim = c(1300, 2300), bty = "l")
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-Amtrakts}
\caption{Amtrak Riderschip as a time series object}
\label{fig:Amtrakts}
\setfloatalignment{b}
\end{figure}

\newthought{Example: Baregg Number of Vehicles as a time series object}
The data are collected daily, starting on 2003-11-01. That is the start of week 44 in the year 2003. When we group them  in a weekly pattern (frequency=7) we can create the following time series object:

<<label=Bareggts, fig=TRUE, include=FALSE, echo=FALSE>>=
number.ts <- ts(Baregg.data$number, start = c(44,1), frequency = 7)
plot(number.ts, xlab = "Time", ylab = "Number of vehicles in Baregg tunnel", ylim = c(50000, 150000), bty = "l")
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-Bareggts}
\caption{Baregg Number of Vehicles as a time series object}
\label{fig:Bareggts}
\setfloatalignment{b}
\end{figure}

\newpage
\subsection{Change the scale}
Meant is: try a transformation. If a trend is exponential, a log-transformation\sidenote{all y-values have to be positive for such a transformation!} will lead to a linear relation, which is much easier to spot. Let's try this for the addcon-time series:

<<label=addconscale, fig=TRUE, include=FALSE, echo=FALSE>>=
ggplot(data=construct, aes(x=t)) +
  geom_line(aes(y=log(addcon)), size=1, color="red") +
  labs(title="Log-transformed addcom time series") +
  JT.theme
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-addconscale}
\caption{}
\label{fig:addconscale}
\setfloatalignment{b}
\end{figure}

\subsection{Add a trend line}
The advice here is to do this preliminary work in Excel (or Numbers). The function "add trendline" allows for a quick an dirty check.

In Figure~\ref{fig:addconnumberstrend}) and Figure~\ref{fig:combiconnumberstrend} we can see the trendlines with the highest $R^{2}$ values. For the ''addcon" time series this a second degree polynomial (surprise!), for the ''combicon" time series it is a power law approximation.

\begin{marginfigure}[-2cm]
\includegraphics[width=0.85\textwidth]{PTSFR-addconnumberstrend}
\caption{Trend with Numbers for addcon}
\label{fig:addconnumberstrend}
\setfloatalignment{b}
\end{marginfigure}

\begin{marginfigure}[0cm]
\includegraphics[width=0.85\textwidth]{PTSFR-combiconnumberstrend}
\caption{Trend with Numbers for combicon}
\label{fig:combiconnumberstrend}
\setfloatalignment{b}
\end{marginfigure}

\newpage
\subsection{Suppressing seasonality}

It is often easier to see trends in the data when seasonality is suppressed. We can use:

<<label=Amtrakagg, fig=TRUE, include=FALSE, echo=FALSE>>=
    Amtrak.data %>% group_by(year(day), quarter(day)) %>% summarise(mean(Ridership)) -> Amtrak.year
    names(Amtrak.year) <- c("year","quarter", "mean")
    Amtrak.year$yrqt <- paste(as.character(Amtrak.year$year), "-", Amtrak.year$quarter)
    Amtrak.year <- as.data.frame(Amtrak.year)
    ggplot(data = Amtrak.year) +
      geom_line(aes(x=yrqt, y= mean, group=1), size=1, color="red") +
      scale_y_continuous(limits= c(1000, 2500)) +
      theme(axis.text.x=element_text(angle=-45, hjust=0.001)) +
      labs(title="Quarterly average of riderschip") +
      JT.theme
@

<<label=Bareggagg, fig=TRUE, include=FALSE, echo=FALSE>>=
    Baregg.data %>% group_by(year(day), month(day)) %>% summarise(mean(number)) -> Baregg.month
    names(Baregg.month) <- c("year", "month","mean")
    Baregg.month$yrmt <- paste(as.character(Baregg.month$year), "-", Baregg.month$month)
    Baregg.month <- as.data.frame(Baregg.month)
    ggplot(data = Baregg.month) +
      geom_line(aes(x=yrmt, y= mean, group=1), size=1, color="red") +
      scale_y_continuous(limits= c(0, 125000)) +
      theme(axis.text.x=element_text(angle=-45, hjust=0.001)) +
      labs(title="Monthly average of numbers in Baregg tunnel") +
      JT.theme
@ 

\begin{itemize}
	\item a larger time scale: aggregating daily data into weeks or months, monthly data into years.
	\begin{enumerate}
	  \item \newthought{Amtrak data}: grouped per quarter (a year is too long)
      \begin{marginfigure}[0cm]
        \includegraphics[width=1\textwidth]{PTSFR-Amtrakagg}
        \caption{Amtrak}
        \label{fig:Amtrakagg}
        \setfloatalignment{b}
      \end{marginfigure}
    \item \newthought{Baregg data}
      \begin{marginfigure}
        \includegraphics[width=1\textwidth]{PTSFR-Bareggagg}
        \caption{Baregg tunnel}
        \label{fig:Bareggagg}
        \setfloatalignment{b}
      \end{marginfigure}
    \end{enumerate}
\end{itemize}

Looking at these results, this seems an awkward way of finding the trend. A lot depends on the choice of the level of aggregation. This does not seem to improve on finding a first idea of the trend by using the inbuilt functions of Excel (of Numbers).

\subsection{Interactive visualization}

Specific software (e.g. Tableau) offer the possibility of visualizing\index{visualization} data dynamically so that you can do a number of the above mentioned techniques (zooming, trending, suppressing seasonality) quickly. As mentioned in \ref{subsec:zoomingin} zooming\index{visualization!zooming} can quickly be done on an existing \textit{ggplot}-object by using the \textbf{plotly}-library. It is not ''Tableau" but it's quick and free.

The book offers more examples of visualization packages that allow you to zoom and filter across multiple data sets. Could be done with \textit{ggplot} and \textit{plotly} but with a great deal of effort!

\section{Data pre-processing}\index{data!quality}

\subsection{Exploratory Data Analysis}\index{EDA = Exploratory Data Analysis}
See EDA.pdf

Using the libraries \textit{broom} and \textit{funModelling} we can get a quick overview of the characteristics of the data frame:

\newthought{Number of rows, variables and head of the first row}
<<>>=
glimpse(Amtrak.data)
@

\newpage
\newthought{Metrics on data types, zeros, infinite numbers, missing values}\index{data!zeros}\index{data!missing values}\index{data!infinite numbers}
<<>>=
df_status(Amtrak.data)
@

\newthought{Distribution of the numerical value}
<<label=dist, fig=TRUE, include=FALSE, echo=FALSE>>=
plot_num(data=Amtrak.data)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-dist}
\caption{distribution of numerical data}
\label{fig:dist}
\setfloatalignment{b}
\end{figure}

\newthought{Checking for extreme values}\index{data!extreme values}
<<>>=
describe(Amtrak.data$Ridership)
@

\subsection{Missing values}\index{data!missing values}

Missing values should turn up in the Exploratory Data Analysis and/or the visualization process. But they can be subtle. So we can detect them by finding the number of values there should be between the start and the end of the time series, and the number of values in the data:

<<echo=TRUE>>=
(interval(ymd(Amtrak.data$day[1]), ymd(Amtrak.data$day[nrow(Amtrak.data)])) %/% months(1) + 1) -
      nrow(Amtrak.data)
(interval(ymd(Baregg.data$day[1]),ymd(Baregg.data$day[nrow(Baregg.data)])) %/% days(1) + 1) -
      nrow(Baregg.data)
@

To check: let's construct a faulty time series: two weeks of data with the weekends missing:
<<>>=
faulty <- data.frame(day = seq(ymd('2012-04-09'), ymd('2012-04-22'), by = '1 day'),
                     y = seq(0:13)) 
faulty$weekday <- wday(faulty$day, label=TRUE)
faulty %>% dplyr::filter(as.character(weekday) != "Sun" &
                         as.character(weekday) !="Sat") -> faulty
(interval(ymd(faulty$day[1]),ymd(faulty$day[nrow(faulty)])) %/% days(1) + 1) - nrow(faulty)
@

Many time-series forecasting methods (such as ARIMA) cannot stand time-series with ''holes". Usually they are filled by \emph{imputation}\index{data!imputing missing values}

Other methods (e.g. linear or logistic regression models) are not influenced when there are missing values.

\subsection{Unequally spaced series}

Spacing can be checked with the \textit{diff}-command:

<<>>=
diff(Amtrak.data$day)
diff(Baregg.data$day)
@

\subsection{Extreme values}\index{data!extreme values}
Extreme values can be discarded if they are unique (e.g. the result of an earthquake) and unlikely to repeat itself in the forecasting period. When in doubt: do two forecasts: one with and one without the extreme values.

\subsection{Choice of time span}\index{forecast!horizon}
How far back in the past should we consider data to be relevant? Older data may have resulted from a different context and environment which are not relevant to the situation in the forecasting period. The rule is the \emph{we extend our time series backwards for only those periods where the environment is assumed to be similar to the forecast horizon}.

\chapter{Performance evaluation}

Using the same data to develop the forecasting model \textbf{and} to assess iets performance, we introduce \emph{bias}\index{bias}\index{performance!bias}. Our model will be fine tuned to this particular set of data. It will not only be adjusted to the systematic component of the data, but also to the noise. The metaphor of the tailor making a perfectly fitting suit for a customer is apt. The suit will not be useful when the customer gains or loses some weight. From this observation follows the idea of partitioning of the data set.

\section{Data partitioning}\index{partition}\index{data!partition}

\emph{Partitioning} is the splitting of the data set into two parts: forecasting models are built using the data in part 1. Using these models we make a forecast of part 2. The differences between the forecasted values and the true values of part 2 are used to measure the performance of different forecasting models.

\subsection{Partitioning of cross-sectional data}

Cross-sectional data\index{data!cross sectional} have values for different variables at one specific moment in time. Then we create three partitions: the \emph{training set}\index{training set}, a \emph{validation set}\index{validation set} and a \emph{test set}\index{test set}. The partitioning is done \emph{at random}: we (the computer) picks at random which data elements go into each set.

\subsection{Temporal partitioning}
When our goal is forecasting, we want to predict the future. Therefore there is no \emph{test set} available. Partitioning is \emph{random} because this would create \emph{missing values}\index{missing values} into both the \emph{training set} and the \emph{validation set}, and it would miss the logical temporal sequence of past and future. Visualization of actual an predicted series for both sets is interesting, because it could indicate overfitting when the predicted and actual series are close to each other in the training period, but not in the validation period.

\subsection{Joining partitions for forecasting}
Before attempting to predict the, unknown, future values we will use our forecasting methods on the whole time series: the joined training and validation sets. This has the following advantages:
\begin{itemize}
	\item the validation period is the most recent and therefore more in tune with the future we wish to forecast
	\item more data can lead to better estimation of model parameters
	\item using only the training set will require that the forecasting must be done further in the future
\end{itemize}

\subsection{Choosing the validation period}
The length of the validation period is determined by the forecast horizon\index{forecast!horizon}. A shorter validation period does not give good information on the quality of our forecasting model at the end of the forecasting period. A longer validation period reduces the amount of data in the training set, and specifically the most recent data.

If we were to make a forecast on the Amtrak data for the next 3 years (=36 months) we would set the validation period nValid to 36. Consequently the training set (nTrain) would be limited to the whole range of Amtrak.data (=nrow(Amtrak.data)) minus nValid. We will be using the times series object that was created before. We include a polynomial regression for the trend. This gives us the following code (you need the library \textbf{forecast}):

<<label=Validationperiod, fig=TRUE, include=FALSE, echo=FALSE>>=
nValid <- 36
nTrain <- length(ridership.ts) - nValid
train.ts <- window(ridership.ts, 
                   start = c(1991, 1), 
                   end = c(1991, nTrain))
valid.ts <- window(ridership.ts, 
                   start = c(1991, nTrain + 1), 
                   end = c(1991, nTrain + nValid))
ridership.lm <- tslm(train.ts ~ trend + I(trend^2))
ridership.lm.pred <- forecast(ridership.lm, h = nValid, level = 0)
plot(ridership.lm.pred, 
     ylim = c(1300, 2600), 
     ylab = "Ridership", 
     xlab = "Time", 
     bty = "l",
     xaxt = "n",
     xlim = c(1991, 2006.25),
     main = "",
     lty = 2)
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006,1)))
lines(ridership.lm$fitted, lwd = 2)
lines(valid.ts)
abline(v = 1991 , col="blue")
abline(v = 1991 + (nTrain)/12 , col="blue")
abline(v = 1991 + (nTrain + nValid)/12, col="blue")
text(x = 1996, y = 2400, labels="Training")
arrows(x0 = 1991, y0 = 2300, 
       x1 = 1991 + nTrain/12, y1 = 2300, 
       code = 3, length = 0.1)
text(x = 2002.6, y = 2400, labels="Validation")
arrows(x0 = 1991 + (nTrain)/12, y0 = 2300, 
       x1 = 1991 + (nTrain + nValid)/12, y1 = 2300, 
       code = 3, length = 0.1)
text(x = 2005.5, y = 2400, labels="Future")
arrows(x0 = 1991 + (nTrain + nValid + 1)/12, y0 = 2300, 
       x1 = 1991 + (nTrain + nValid + 36)/12, y1 = 2300, 
       code = 2, length = 0.1)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-Validationperiod}
\caption{Amtrak Riderschip validation period}
\label{fig:Validationperiod}
\setfloatalignment{b}
\end{figure}

\section{Naive forecasts}\index{forecast!naive}

\emph{Naive forecasts} have the merit that they are simple, easy to understand and, in some cases, are sufficient to achieve the forecasting goal. If not, their performance can by used as a benchmark for more complicated model.

\begin{itemize}
	\item For a time series that does not show substantial seasonality, or if the seasonality has a period that is much greater than the forecast horizon, the \emph{naive} forecast is \emph{the most recent value} of the time series. The k-step-ahead forecast is:
    \begin{equation}
    	F_{t_{latest}+k} = y_{t_{latest}} = constant
    \end{equation}
        Graphically it means that the forecasted values are on a horizontal line for the whole forecasting horizon.
  \item For a time series with seasonality with known period T that extends into the forecasting horizon the \emph{naive} forecast is \emph{the value - 1 period} of the time series. The k-step-ahead forecast is:
    \begin{equation}
    	F_{t_{latest} + 1} = y_{t_{latest} + 1 - T}
    \end{equation}
        Graphically it means that the forecasted values are a repeat of the last known period
\end{itemize}

It is the equivalent of the principle of \emph{persistency} that is used as a naive forecast in weather forecasting.

\section{Measuring predictive accuray}\index{accuracy}\index{forecast!accuracy}

\emph{Predictive accuracy} is not the same as \emph{Goodness of Fit}. The latter measure how well the model fits the data. In forecasting however we are interested in the question of how wel the model, based on the \emph{training set}, predicts the values in the \emph{validation set}.

\subsection{Metrics for prediction accurary}\index{forecast!accuracy metrics}

The \emph{forecast error}\index{forecast!error}\index{forecast!accuracy} or \emph{residual}\index{residual} is the difference between the actual value $y_{t}$ and the forecast value $F_{t}$:
\begin{equation}
	e_{t}=y_{t} - F_{t}
\end{equation}

The validation set has time indexes $t_{start + n_{Train}} + i$, with $i=1 \ldots n_{Valid}$, than we can define the following metrics:
\begin{itemize}
	\item Mean Absolute Error (or Deviation) (MAE of MAD)
	  \begin{equation}
	    MAE = \frac{1}{n_{Valid}}\sum_{1}^{n_{Valid}} |e_{i}|
    \end{equation}
  \item Average Error: idem but without the absolute values. Gives an idea of under- or overprediction
     \begin{equation}
	    MAE = \frac{1}{n_{Valid}}\sum_{1}^{n_{Valid}} e_{i}
    \end{equation}
  \item Mean Absolute Percentage Error: relative absolute error. Used when comparing performance across time series with different scales
     \begin{equation}
	    MAPE = \frac{1}{n_{Valid}}\sum_{1}^{n_{Valid}}| \frac{e_{i}}{y_{i}}*100 | 
    \end{equation}
  \item Root Mean Square Error
    \begin{equation}
	    RMSE = \sqrt{ \frac{1}{n_{Valid}}\sum_{1}^{n_{Valid}} e_{i}^{2} }
    \end{equation}
\end{itemize}

Applying these principles and definitons to the Amtrak.data time series we get:

<<>>=
forecast.error <- valid.ts - ridership.lm.pred$mean
MAE <- (1/nValid)*sum(abs(forecast.error))
MAE
AvEr <- (1/nValid)*sum(forecast.error)
AvEr
MAPE <- (1/nValid)*sum(abs(forecast.error*100/valid.ts))
MAPE
RMSE <- sqrt((1/nValid)*sum(forecast.error^2))
RMSE
@

or we immediately use the \textit{accuracy}-function\index{accuracy}\index{forecast!accuracy}:
<<>>=
accuracy(ridership.lm.pred$mean, valid.ts)
@

\subsection{Zero counts}
Calculating MAPE is impossible when $y_{i}=0$. When you cannot reasonably exclude these values, another metric is used: the MASE = Mean Absolute Scaled Error. It devides the model MAE by the MAE of the naive forecast \emph{on the training set}:

\begin{equation}
	MASE = \frac{validation MAE}{training MAE of naive forecast} = \frac{\frac{1}{n_{Valid}}\sum_{1}^{n_{Valid}} |e_{i}|}{\frac{1}{n_{Train}-1}\sum_{1}^{n_{Train}} |y_{t-1} - y_{t}|}
\end{equation}

Values of MASE lower higher than 1 indicate a poorer performance than the naive forecast.

\subsection{Forecast accuracy vs. profitability}\index{forecast!accuracy}\index{forecast!cost}
Some metrics (e.g. MAPE and RMSE) inflate the effect of large errors. But the effects, or costs, of the error should also come into consideration. Sometimes the cost of a forecast error is big for positive errors, but not for negative ones. Sometimes the cost is proportional to the error, but the relation can be non-linear: it can be that the cost is the same once a certain error treshold is crossed.A measure of profitability could be very usefull when choosing the forecast method.

\section{Evaluating forecast uncertainty}

\subsection{Distribution of forecast errors}

We should go beyond the clustered metrics like MAPE or RMSE. It is interesting to examine the distribution of forecasting errors: are there extremely low or high errors. For example: we have constructed a second degree polynomial trend model (ridership.lm) based on the training set. Using this model we can predict the ridership data both for the training set and for the validation set (ridership.lm.pred).

<<label=Residuals, fig=TRUE, include=FALSE, echo=FALSE>>=
par(mfrow = c(2,1))
plot(ridership.lm.pred$residuals, 
     ylim = c(-400, 400), 
     ylab = "Residuals", 
     xlab = "Time", 
     bty = "l",
     xaxt = "n",
     xlim = c(1991, 2006.25),
     main = "",
     lty = 1)
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006,1)))
lines(valid.ts - ridership.lm.pred$mean)
abline(v = 1991 , col="blue")
abline(v = 1991 + (nTrain)/12 , col="blue")
abline(v = 1991 + (nTrain + nValid)/12, col="blue")
text(x = 1996, y = 350, labels="Training")
arrows(x0 = 1991, y0 = 300, 
       x1 = 1991 + nTrain/12, y1 = 300, 
       code = 3, length = 0.1)
text(x = 2002.6, y = 350, labels="Validation")
arrows(x0 = 1991 + (nTrain)/12, y0 = 300, 
       x1 = 1991 + (nTrain + nValid)/12, y1 = 300, 
       code = 3, length = 0.1)
text(x = 2005.5, y = 350, labels="Future")
arrows(x0 = 1991 + (nTrain + nValid + 1)/12, y0 = 300, 
       x1 = 1991 + (nTrain + nValid + 36)/12, y1 = 300, 
       code = 2, length = 0.1)
hist(ridership.lm.pred$residuals, 
     ylab = "Frequency", 
     xlab = "Residuals", 
     bty = "l", 
     main = "")
par(mfrow=c(1,1))
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-Residuals}
\caption{Amtrak Riderschip Residuals}
\label{fig:Residuals}
\setfloatalignment{b}
\end{figure}

\subsection{Prediction intervals}
A \emph{prediction intervel}\index{prediction interval} gives a confidence interval\index{confidence interval} of the forecast. If the forecast error is normally distributed we can use standard techniques to calculate the confidence intervals. For forecast models where the error does not have a normal distribution (e.g. the Amtrak second order polynomial model with residuals given in Figure\ref{fig:Residuals}) we can use the 5th and 95th quantile from the residuals to construct a confidence interval.

\subsection{Prediction cones}
Certain forecast models will have confidence intervals that become larger when our forecasts are made for points more and more into the future.

\section{Advanced Data Partitioning: roll-forward validation}\index{roll-forward validation}
When we partition the time series into one, fixed, training set and one, fixed, validation set then our forecasting method will give us only one prediction trajectory into the future.

When using \emph{roll-forward validation} we have a number of partitions where we start from one training/validation combination, and make new training/validation sets by extending the training set with one period, and consequently reduce the validation set with the same period. For example: with the Amtrak time series we started with a validation set that had 36 months. With \emph{roll-forward validation} we create 36 partitionings where the validation set has 36, 35, 34 ... 1 months of data, and the training set grows each time with one month. When we keep the forecast horizon equal to the length of the validation set, we will get forecasts for 36 months from the first partition, 35 months from the second, ending with 1 month forecast from the last partition. This means that in the end we will have 36 forecasts for month 1 into the future, 35 forecasts for mont 2 into the future and 1 forecast for month 36 into the future. Roll-forward partitioning is also a good choice when our time series is dynamic and we get new information on a steady basis. Our time series grows in time, and we can enlarge the training set and reduce the validation set if the forecast date(s) remain the same.

For example: if we use a very simple forecast model (naive, only trend), then for the fixed partition our model for the next 36 months is a constant equal to the last value of $y_{i}$ in the training set.

<<>>=
forecast.fixed <- rep(last(train.ts), nValid)
forecast.fixed.ts <- ts(forecast.fixed, 
                        start = c(2001,4), 
                        end = c(2004, 3), 
                        freq = 12)
@

In a \emph{roll-forward validation} we 

\begin{itemize}
	\item start with a 36 period validation set, which gives 36 forecasts for the future equal to the last value in the training set
	\item continue with a 35 period validation set, resulting in 35 forecast equal to the last value of the training set \textbf{+ 1}. This is the first value in the fixed validation set
	\item a 34 period validation set, with 34 forecasts equal to the second value in the fixed validation set
	\item ...
	\item a 1 period validation set, with 1 forecast equal to the last value \textbf{but one} in the fixed validation set
\end{itemize}

The forecasts are thus given by:
<<>>=
forecast.roll.fwd <- append(last(train.ts), valid.ts[1:(length(valid.ts)-1)])
forecast.roll.fwd.ts <- ts(forecast.roll.fwd, 
                           start = c(2001,4), 
                           end = c(2004, 3), 
                           freq = 12)
@

<<label=rollforward, fig=TRUE, include=FALSE, echo=FALSE>>=
plot(ridership.lm.pred, 
     ylim = c(1300, 2600), 
     ylab = "Ridership", 
     xlab = "Time", 
     bty = "l",
     xaxt = "n",
     xlim = c(1991, 2006.25),
     main = "",
     lty = 1)
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006,1)))
lines(ridership.lm$fitted, lwd = 2)
lines(valid.ts, lty = 1)
lines(forecast.fixed.ts, lty = 3, col="red")
lines(forecast.roll.fwd.ts, lty = 2, col="red")
abline(v = 1991 , col="blue")
abline(v = 1991 + (nTrain)/12 , col="blue")
abline(v = 1991 + (nTrain + nValid)/12, col="blue")
text(x = 1996, y = 2400, labels="Training")
arrows(x0 = 1991, y0 = 2300, 
       x1 = 1991 + nTrain/12, y1 = 2300, 
       code = 3, length = 0.1)
text(x = 2002.6, y = 2400, labels="Validation")
arrows(x0 = 1991 + (nTrain)/12, y0 = 2300, 
       x1 = 1991 + (nTrain + nValid)/12, y1 = 2300, 
       code = 3, length = 0.1)
text(x = 2005.5, y = 2400, labels="Future")
arrows(x0 = 1991 + (nTrain + nValid + 1)/12, y0 = 2300, 
       x1 = 1991 + (nTrain + nValid + 36)/12, y1 = 2300, 
       code = 2, length = 0.1)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{PTSFR-Rollforward}
\caption{Amtrak Riderschip roll-forward validation}
\label{fig:Rollforward}
\setfloatalignment{b}
\end{figure}

However, this is not a good example! Of course our forecast in the validation period is better because we use the actual data from that period! We could have made it a perfect fit by choosing the actual last data point instead of the data point minus 1. A better example would be to determine the second degree polynomial model based on the dynamic training set and calculate the forecasting metrics using the dynamic validation set.

\section{Example: comparing two models}

Using the Amtrak ridership data we compare two forecast methods: naive and seasonal naive. For both we use fixed partitioning and roll-forward partitioning. \textsf{R} packages like \textit{forecast} have functions \textit{naive} and \textit{snaive} that generate the forecast models.

\subsection{Fixed partitioning}

<<>>=
fixed.nValid <- 36
fixed.nTrain <- length(ridership.ts) - fixed.nValid
train.ts <- window(ridership.ts, 
                   start = c(1991, 1),
                   end = c(1991, fixed.nTrain))
valid.ts <- window(ridership.ts, 
                   start = c(1991, fixed.nTrain + 1), 
                   end = c(1991, fixed.nTrain + fixed.nValid))
naive.pred <- naive(train.ts, h = fixed.nValid)
snaive.pred <- snaive(train.ts, h = fixed.nValid)
accuracy(naive.pred, valid.ts)
accuracy(snaive.pred, valid.ts)
@

\subsection{Roll-forward partitioning}

<<>>=
fixed.nValid <- 36
fixed.nTrain <- length(ridership.ts) - fixed.nValid
stepsAhead <- 1
error.naive <- rep(0, fixed.nValid - stepsAhead + 1)
percent.error.naive <- rep(0, fixed.nValid - stepsAhead + 1)
error.snaive <- rep(0, fixed.nValid - stepsAhead + 1)
percent.error.snaive <- rep(0, fixed.nValid - stepsAhead + 1)
for  (j in fixed.nTrain:(fixed.nTrain + fixed.nValid - stepsAhead)) {
  train.ts <- window(ridership.ts, 
                    start = c(1991, 1),
                    end = c(1991, j))
  valid.ts <- window(ridership.ts, 
                   start = c(1991, j + stepsAhead), 
                   end = c(1991, fixed.nTrain + fixed.nValid))
  naive.pred <- naive(train.ts, h = stepsAhead)
  snaive.pred <- snaive(train.ts, h = stepsAhead)
  error.naive[j - fixed.nTrain + 1] <- valid.ts - naive.pred$mean[stepsAhead]
  percent.error.naive[j - fixed.nTrain + 1] <- error.naive[j - fixed.nTrain + 1]/valid.ts
  error.snaive[j - fixed.nTrain + 1] <- valid.ts - snaive.pred$mean[stepsAhead]
  percent.error.snaive[j - fixed.nTrain + 1] <- error.snaive[j - fixed.nTrain + 1]/valid.ts
}
print("naive")
mean(abs(error.naive))
sqrt(mean(error.naive^2))
mean(abs(percent.error.naive))
print("snaive")
mean(abs(error.snaive))
sqrt(mean(error.snaive^2))
mean(abs(percent.error.snaive))
@

\chapter{Forecasting methods: overview}

\section{Model-based vs. Data-driven methods}\index{forecast!model-based methods}\index{forecast!data-driven methods}\index{model-based methods}\index{data-driven methods}\index{methods!model-based}\index{methods!data-driven}



\printindex

\newpage

\textbf{Thanks} \\
\medskip
R Core Team (2018). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.
\medskip
<<>>=
sessionInfo()
@

\end{document}